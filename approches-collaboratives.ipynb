{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approches collaboratives : utilisateur-utilisateur, item-item\n",
    "\n",
    "Pierrick DOSSIN  \n",
    "Guillaume RIU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import random\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>item.id</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>1673</th>\n",
       "      <th>1674</th>\n",
       "      <th>1675</th>\n",
       "      <th>1676</th>\n",
       "      <th>1677</th>\n",
       "      <th>1678</th>\n",
       "      <th>1679</th>\n",
       "      <th>1680</th>\n",
       "      <th>1681</th>\n",
       "      <th>1682</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user.id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1682 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "item.id  1     2     3     4     5     6     7     8     9     10    ...  \\\n",
       "user.id                                                              ...   \n",
       "1         5.0   3.0   4.0   3.0   3.0   5.0   4.0   1.0   5.0   3.0  ...   \n",
       "2         4.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   2.0  ...   \n",
       "3         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "4         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "5         4.0   3.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "\n",
       "item.id  1673  1674  1675  1676  1677  1678  1679  1680  1681  1682  \n",
       "user.id                                                              \n",
       "1         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "2         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "3         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "4         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "5         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "\n",
       "[5 rows x 1682 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "votes = pd.read_csv('Data/votes.csv')\n",
    "\n",
    "# Matrice Utilisateur Item\n",
    "MUI = votes.pivot(index=\"user.id\", columns=\"item.id\", values=\"rating\")\n",
    "MUI_numpy = MUI.to_numpy()\n",
    "MUI_numpy_flat = MUI_numpy.reshape(-1)\n",
    "\n",
    "MUI.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Définition des métriques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erreur quadratique moyenne\n",
    "def MSE_mat(y_pred, y_true):\n",
    "    return np.nanmean((y_pred - y_true)**2)\n",
    "\n",
    "# Erreur absolue moyenne\n",
    "def MAE_mat(y_pred, y_true):\n",
    "    return np.nanmean(np.abs(y_pred - y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommandations_list(votes_predits, nmb_reco):\n",
    "    # liste des meilleurs recommandations n'ayant pas déjà été vues\n",
    "    return np.argsort(np.array(-votes_predits * np.isnan(MUI)))[:,:nmb_reco]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diversite(votes_observes, votes_predits, nmb_reco):\n",
    "    diversite = 0\n",
    "    reco = recommandations_list(votes_predits, nmb_reco)\n",
    "    votes_observes = votes_observes.replace(np.nan, 0)\n",
    "    # Matrice des similarités item selon les votes observés\n",
    "    cosine_similarity = 1 - pairwise_distances(votes_observes.T, metric=\"cosine\")\n",
    "    for u in range(votes_observes.shape[0]):\n",
    "        for i in range(nmb_reco):\n",
    "            for j in range(nmb_reco):\n",
    "                if i!= j:\n",
    "                    diversite += cosine_similarity[reco[u][i], reco[u][j]]\n",
    "    diversite /= nmb_reco * (nmb_reco - 1) * votes_observes.shape[0]\n",
    "    return diversite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nouveaute(votes_observes, votes_predits, nmb_reco):\n",
    "    nouveaute = 0\n",
    "    reco = recommandations_list(votes_predits, nmb_reco)\n",
    "    MUI_zero_one = votes_observes.replace(np.nan, 0)\n",
    "    MUI_zero_one[MUI_zero_one > 0] = 1\n",
    "    proportion_visionnage_item = np.nanmean(MUI_zero_one, axis=0)\n",
    "    for u in range(votes_observes.shape[0]):\n",
    "        for i in range(nmb_reco):\n",
    "            nouveaute += -np.log2(proportion_visionnage_item[reco[u][i]])\n",
    "    nouveaute /= nmb_reco * len(votes_observes)\n",
    "    return nouveaute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def couverture(votes_observes, votes_predits, nmb_reco):\n",
    "    reco = recommandations_list(votes_predits, nmb_reco)\n",
    "    nb_item_reco = len(np.unique(reco))\n",
    "    nb_item = votes_observes.shape[1]\n",
    "    couverture = nb_item_reco / nb_item\n",
    "    return couverture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def utilite(votes_observes, votes_predits, nmb_reco):\n",
    "    # Moyenne des meilleurs recommandations\n",
    "    reco = np.sort(np.array(-votes_predits * np.isnan(MUI)))[:,:nmb_reco]\n",
    "    return -np.mean(reco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p(MUI_nan, i, j = None):\n",
    "    if (j==None):\n",
    "        nan = sum(MUI_nan[:,i]) \n",
    "        return (MUI.shape[0] - nan) / MUI.shape[0]\n",
    "    else:\n",
    "        nan = sum(MUI_nan[:,i] * MUI_nan[:,j])\n",
    "        return (MUI.shape[0] - nan) / MUI.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aime_list(votes_observes, nmb_reco):\n",
    "    MUI_zero_one = votes_observes.replace(np.nan, 0)\n",
    "    return np.argsort(np.array(-MUI_zero_one))[:,:nmb_reco]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serendipite(votes_observes, votes_predits, nmb_reco):\n",
    "    MUI_nan = np.array(np.isnan(votes_observes))\n",
    "    reco = recommandations_list(votes_predits, nmb_reco)\n",
    "    aime = aime_list(votes_observes, nmb_reco)\n",
    "    pmi = 0\n",
    "    for u in range(votes_observes.shape[0]):\n",
    "        for i in reco[u]:\n",
    "            for j in aime[u]:\n",
    "                pmi += np.log2(p(MUI_nan, i,j)/(p(MUI_nan, i)*p(MUI_nan, j)))\n",
    "    pmi /= nmb_reco * nmb_reco * votes_observes.shape[0]\n",
    "    return pmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcul_facteur(votes_observes, votes_predits, facteur, nmb_reco):\n",
    "    if facteur == \"serendipite\":\n",
    "        return serendipite(votes_observes, votes_predits, nmb_reco)\n",
    "    elif facteur == \"utilite\":\n",
    "        return utilite(votes_observes, votes_predits, nmb_reco)\n",
    "    elif facteur == \"couverture\":\n",
    "        return couverture(votes_observes, votes_predits, nmb_reco)\n",
    "    elif facteur == \"nouveaute\":\n",
    "        return nouveaute(votes_observes, votes_predits, nmb_reco)\n",
    "    elif facteur == \"diversite\":\n",
    "        return diversite(votes_observes, votes_predits, nmb_reco)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prédictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création des indices pour les valeurs différentes de np.nan\n",
    "indices = np.arange(0, MUI_numpy.shape[0]*MUI_numpy.shape[1])\n",
    "indices_na = indices[~np.isnan(MUI_numpy_flat)]\n",
    "\n",
    "# Split Train Test des indices\n",
    "nb_replis = 5\n",
    "np.random.shuffle(indices_na)\n",
    "idx_split = np.split(indices_na, nb_replis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pierr\\AppData\\Local\\Temp\\ipykernel_2236\\2320157975.py:88: RuntimeWarning: invalid value encountered in divide\n",
      "  pred_sans_biais_u = w_u.dot(MUI_train_zero) / abs(w_u).dot(MUI_train_zero_one)\n",
      "C:\\Users\\pierr\\AppData\\Local\\Temp\\ipykernel_2236\\2320157975.py:96: RuntimeWarning: Mean of empty slice\n",
      "  MUI_train_means_I = np.expand_dims(np.nanmean(MUI_train, axis=0), axis=0)\n",
      "C:\\Users\\pierr\\AppData\\Local\\Temp\\ipykernel_2236\\2320157975.py:99: RuntimeWarning: invalid value encountered in divide\n",
      "  pred_avec_biais_u = w_u.dot(MUI_train_norm_U) / abs(w_u).dot(MUI_train_zero_one) + MUI_train_means_U\n",
      "C:\\Users\\pierr\\AppData\\Local\\Temp\\ipykernel_2236\\2320157975.py:117: RuntimeWarning: invalid value encountered in divide\n",
      "  pred_100_neighboors_u = w_u_100_neighboors.dot(MUI_train_norm_U) / abs(w_u_100_neighboors).dot(MUI_train_zero_one) + MUI_train_means_U\n",
      "C:\\Users\\pierr\\AppData\\Local\\Temp\\ipykernel_2236\\2320157975.py:88: RuntimeWarning: invalid value encountered in divide\n",
      "  pred_sans_biais_u = w_u.dot(MUI_train_zero) / abs(w_u).dot(MUI_train_zero_one)\n",
      "C:\\Users\\pierr\\AppData\\Local\\Temp\\ipykernel_2236\\2320157975.py:96: RuntimeWarning: Mean of empty slice\n",
      "  MUI_train_means_I = np.expand_dims(np.nanmean(MUI_train, axis=0), axis=0)\n",
      "C:\\Users\\pierr\\AppData\\Local\\Temp\\ipykernel_2236\\2320157975.py:99: RuntimeWarning: invalid value encountered in divide\n",
      "  pred_avec_biais_u = w_u.dot(MUI_train_norm_U) / abs(w_u).dot(MUI_train_zero_one) + MUI_train_means_U\n",
      "C:\\Users\\pierr\\AppData\\Local\\Temp\\ipykernel_2236\\2320157975.py:117: RuntimeWarning: invalid value encountered in divide\n",
      "  pred_100_neighboors_u = w_u_100_neighboors.dot(MUI_train_norm_U) / abs(w_u_100_neighboors).dot(MUI_train_zero_one) + MUI_train_means_U\n",
      "C:\\Users\\pierr\\AppData\\Local\\Temp\\ipykernel_2236\\2320157975.py:88: RuntimeWarning: invalid value encountered in divide\n",
      "  pred_sans_biais_u = w_u.dot(MUI_train_zero) / abs(w_u).dot(MUI_train_zero_one)\n",
      "C:\\Users\\pierr\\AppData\\Local\\Temp\\ipykernel_2236\\2320157975.py:96: RuntimeWarning: Mean of empty slice\n",
      "  MUI_train_means_I = np.expand_dims(np.nanmean(MUI_train, axis=0), axis=0)\n",
      "C:\\Users\\pierr\\AppData\\Local\\Temp\\ipykernel_2236\\2320157975.py:99: RuntimeWarning: invalid value encountered in divide\n",
      "  pred_avec_biais_u = w_u.dot(MUI_train_norm_U) / abs(w_u).dot(MUI_train_zero_one) + MUI_train_means_U\n",
      "C:\\Users\\pierr\\AppData\\Local\\Temp\\ipykernel_2236\\2320157975.py:117: RuntimeWarning: invalid value encountered in divide\n",
      "  pred_100_neighboors_u = w_u_100_neighboors.dot(MUI_train_norm_U) / abs(w_u_100_neighboors).dot(MUI_train_zero_one) + MUI_train_means_U\n",
      "C:\\Users\\pierr\\AppData\\Local\\Temp\\ipykernel_2236\\2320157975.py:88: RuntimeWarning: invalid value encountered in divide\n",
      "  pred_sans_biais_u = w_u.dot(MUI_train_zero) / abs(w_u).dot(MUI_train_zero_one)\n",
      "C:\\Users\\pierr\\AppData\\Local\\Temp\\ipykernel_2236\\2320157975.py:96: RuntimeWarning: Mean of empty slice\n",
      "  MUI_train_means_I = np.expand_dims(np.nanmean(MUI_train, axis=0), axis=0)\n",
      "C:\\Users\\pierr\\AppData\\Local\\Temp\\ipykernel_2236\\2320157975.py:99: RuntimeWarning: invalid value encountered in divide\n",
      "  pred_avec_biais_u = w_u.dot(MUI_train_norm_U) / abs(w_u).dot(MUI_train_zero_one) + MUI_train_means_U\n",
      "C:\\Users\\pierr\\AppData\\Local\\Temp\\ipykernel_2236\\2320157975.py:117: RuntimeWarning: invalid value encountered in divide\n",
      "  pred_100_neighboors_u = w_u_100_neighboors.dot(MUI_train_norm_U) / abs(w_u_100_neighboors).dot(MUI_train_zero_one) + MUI_train_means_U\n",
      "C:\\Users\\pierr\\AppData\\Local\\Temp\\ipykernel_2236\\2320157975.py:88: RuntimeWarning: invalid value encountered in divide\n",
      "  pred_sans_biais_u = w_u.dot(MUI_train_zero) / abs(w_u).dot(MUI_train_zero_one)\n",
      "C:\\Users\\pierr\\AppData\\Local\\Temp\\ipykernel_2236\\2320157975.py:96: RuntimeWarning: Mean of empty slice\n",
      "  MUI_train_means_I = np.expand_dims(np.nanmean(MUI_train, axis=0), axis=0)\n",
      "C:\\Users\\pierr\\AppData\\Local\\Temp\\ipykernel_2236\\2320157975.py:99: RuntimeWarning: invalid value encountered in divide\n",
      "  pred_avec_biais_u = w_u.dot(MUI_train_norm_U) / abs(w_u).dot(MUI_train_zero_one) + MUI_train_means_U\n",
      "C:\\Users\\pierr\\AppData\\Local\\Temp\\ipykernel_2236\\2320157975.py:117: RuntimeWarning: invalid value encountered in divide\n",
      "  pred_100_neighboors_u = w_u_100_neighboors.dot(MUI_train_norm_U) / abs(w_u_100_neighboors).dot(MUI_train_zero_one) + MUI_train_means_U\n"
     ]
    }
   ],
   "source": [
    "# Liste des erreurs MSE et MAE pour chacun des 5 plis de la validation croisée\n",
    "\n",
    "MSE_votes_sans_biais_u = []\n",
    "MSE_votes_avec_biais_u = []\n",
    "MSE_votes_voisins_rapproches_u = []\n",
    "\n",
    "MSE_votes_sans_biais_i = []\n",
    "MSE_votes_avec_biais_i = []\n",
    "MSE_votes_voisins_rapproches_i = []\n",
    "\n",
    "MAE_votes_sans_biais_u = []\n",
    "MAE_votes_avec_biais_u = []\n",
    "MAE_votes_voisins_rapproches_u = []\n",
    "\n",
    "MAE_votes_sans_biais_i = []\n",
    "MAE_votes_avec_biais_i = []\n",
    "MAE_votes_voisins_rapproches_i = []\n",
    "\n",
    "# Liste des facteurs de succès pour chacun des 5 plis de la validation croisée\n",
    "\n",
    "serendipite_votes_sans_biais_u = []\n",
    "serendipite_votes_avec_biais_u = []\n",
    "serendipite_votes_voisins_rapproches_u = []\n",
    "\n",
    "serendipite_votes_sans_biais_i = []\n",
    "serendipite_votes_avec_biais_i = []\n",
    "serendipite_votes_voisins_rapproches_i = []\n",
    "\n",
    "utilite_votes_sans_biais_u = []\n",
    "utilite_votes_avec_biais_u = []\n",
    "utilite_votes_voisins_rapproches_u = []\n",
    "\n",
    "utilite_votes_sans_biais_i = []\n",
    "utilite_votes_avec_biais_i = []\n",
    "utilite_votes_voisins_rapproches_i = []\n",
    "\n",
    "couverture_votes_sans_biais_u = []\n",
    "couverture_votes_avec_biais_u = []\n",
    "couverture_votes_voisins_rapproches_u = []\n",
    "\n",
    "couverture_votes_sans_biais_i = []\n",
    "couverture_votes_avec_biais_i = []\n",
    "couverture_votes_voisins_rapproches_i = []\n",
    "\n",
    "nouveaute_votes_sans_biais_u = []\n",
    "nouveaute_votes_avec_biais_u = []\n",
    "nouveaute_votes_voisins_rapproches_u = []\n",
    "\n",
    "nouveaute_votes_sans_biais_i = []\n",
    "nouveaute_votes_avec_biais_i = []\n",
    "nouveaute_votes_voisins_rapproches_i = []\n",
    "\n",
    "diversite_votes_sans_biais_u = []\n",
    "diversite_votes_avec_biais_u = []\n",
    "diversite_votes_voisins_rapproches_u = []\n",
    "\n",
    "diversite_votes_sans_biais_i = []\n",
    "diversite_votes_avec_biais_i = []\n",
    "diversite_votes_voisins_rapproches_i = []\n",
    "\n",
    "\n",
    "for i in range(nb_replis):\n",
    "    \n",
    "    # Liste d'indice train et test\n",
    "    idx_train = np.delete(idx_split, i, axis=0).flatten()\n",
    "    idx_test  = idx_split[i]\n",
    "\n",
    "    # On enlève les valeurs de test de la matrice d'entrainement\n",
    "    MUI_numpy_flat_train = MUI_numpy_flat.copy()\n",
    "    MUI_numpy_flat_test  = MUI_numpy_flat.copy()\n",
    "    MUI_numpy_flat_train[idx_test] = np.nan\n",
    "    MUI_numpy_flat_test[idx_train] = np.nan\n",
    "\n",
    "    MUI_train = pd.DataFrame(MUI_numpy_flat_train.reshape(MUI_numpy.shape))\n",
    "    MUI_test  = pd.DataFrame(MUI_numpy_flat_test.reshape(MUI_numpy.shape))\n",
    "\n",
    "    MUI_train_zero_one = MUI_train.replace(np.nan, 0)\n",
    "    MUI_train_zero_one[MUI_train_zero_one > 0] = 1\n",
    "\n",
    "    MUI_train_zero = MUI_train.replace(np.nan, 0)\n",
    "\n",
    "\n",
    "    # Vote sans correction biais\n",
    "\n",
    "    w_u = 1 - pairwise_distances(MUI_train_zero, metric=\"cosine\")\n",
    "    w_i = 1 - pairwise_distances(MUI_train_zero.T, metric=\"cosine\")\n",
    "\n",
    "    pred_sans_biais_u = w_u.dot(MUI_train_zero) / abs(w_u).dot(MUI_train_zero_one)\n",
    "    pred_sans_biais_i = np.array(MUI_train_zero.dot(w_i) / MUI_train_zero_one.dot(abs(w_i)))\n",
    "\n",
    "    # Vote avec correction biais\n",
    "\n",
    "    MUI_train_means_U = np.expand_dims(np.nanmean(MUI_train, axis=1), axis=-1)\n",
    "    MUI_train_norm_U = (MUI_train - MUI_train_means_U).replace(np.nan, 0)\n",
    "\n",
    "    MUI_train_means_I = np.expand_dims(np.nanmean(MUI_train, axis=0), axis=0)\n",
    "    MUI_train_norm_I = (MUI_train - MUI_train_means_I).replace(np.nan, 0)\n",
    "\n",
    "    pred_avec_biais_u = w_u.dot(MUI_train_norm_U) / abs(w_u).dot(MUI_train_zero_one) + MUI_train_means_U\n",
    "    pred_avec_biais_i = np.array(MUI_train_norm_I.dot(w_i) / MUI_train_zero_one.dot(abs(w_i)) + MUI_train_means_I)\n",
    "\n",
    "    # Vote 100 voisins rapprochés\n",
    "\n",
    "    w_u_100_neighboors = w_u.copy()\n",
    "    w_i_100_neighboors = w_i.copy()\n",
    "\n",
    "    for u in w_u_100_neighboors:\n",
    "        ind = np.argpartition(u, -100)[:-100]\n",
    "        u[ind] = 0\n",
    "\n",
    "    for i in w_i_100_neighboors:\n",
    "        ind = np.argpartition(i, -100)[:-100]\n",
    "        i[ind] = 0\n",
    "\n",
    "    w_i_100_neighboors = w_i_100_neighboors.T\n",
    "\n",
    "    pred_100_neighboors_u = w_u_100_neighboors.dot(MUI_train_norm_U) / abs(w_u_100_neighboors).dot(MUI_train_zero_one) + MUI_train_means_U\n",
    "    pred_100_neighboors_i = np.array(MUI_train_norm_I.dot(w_i_100_neighboors) / MUI_train_zero_one.dot(abs(w_i_100_neighboors)) + MUI_train_means_I)\n",
    "\n",
    "\n",
    "    MSE_votes_sans_biais_u.append(MSE_mat(pred_sans_biais_u, MUI_test))\n",
    "    MAE_votes_sans_biais_u.append(MAE_mat(pred_sans_biais_u, MUI_test))\n",
    "\n",
    "    MSE_votes_avec_biais_u.append(MSE_mat(pred_avec_biais_u, MUI_test))\n",
    "    MAE_votes_avec_biais_u.append(MAE_mat(pred_avec_biais_u, MUI_test))\n",
    "\n",
    "    MSE_votes_voisins_rapproches_u.append(MSE_mat(pred_100_neighboors_u, MUI_test))\n",
    "    MAE_votes_voisins_rapproches_u.append(MAE_mat(pred_100_neighboors_u, MUI_test))\n",
    "\n",
    "    MSE_votes_sans_biais_i.append(MSE_mat(pred_sans_biais_i, MUI_test))\n",
    "    MAE_votes_sans_biais_i.append(MAE_mat(pred_sans_biais_i, MUI_test))\n",
    "\n",
    "    MSE_votes_avec_biais_i.append(MSE_mat(pred_avec_biais_i, MUI_test))\n",
    "    MAE_votes_avec_biais_i.append(MAE_mat(pred_avec_biais_i, MUI_test))\n",
    "\n",
    "    MSE_votes_voisins_rapproches_i.append(MSE_mat(pred_100_neighboors_i, MUI_test))\n",
    "    MAE_votes_voisins_rapproches_i.append(MAE_mat(pred_100_neighboors_i, MUI_test))\n",
    "\n",
    "\n",
    "    serendipite_votes_sans_biais_u.append(calcul_facteur(MUI, pred_sans_biais_u, \"serendipite\", 10))\n",
    "    utilite_votes_sans_biais_u.append(calcul_facteur(MUI, pred_sans_biais_u, \"utilite\", 10))\n",
    "    couverture_votes_sans_biais_u.append(calcul_facteur(MUI, pred_sans_biais_u, \"couverture\", 10))\n",
    "    nouveaute_votes_sans_biais_u.append(calcul_facteur(MUI, pred_sans_biais_u, \"nouveaute\", 10))\n",
    "    diversite_votes_sans_biais_u.append(calcul_facteur(MUI, pred_sans_biais_u, \"diversite\", 10))\n",
    "\n",
    "    serendipite_votes_avec_biais_u.append(calcul_facteur(MUI, pred_avec_biais_u, \"serendipite\", 10))\n",
    "    utilite_votes_avec_biais_u.append(calcul_facteur(MUI, pred_avec_biais_u, \"utilite\", 10))\n",
    "    couverture_votes_avec_biais_u.append(calcul_facteur(MUI, pred_avec_biais_u, \"couverture\", 10))\n",
    "    nouveaute_votes_avec_biais_u.append(calcul_facteur(MUI, pred_avec_biais_u, \"nouveaute\", 10))\n",
    "    diversite_votes_avec_biais_u.append(calcul_facteur(MUI, pred_avec_biais_u, \"diversite\", 10))\n",
    "\n",
    "    serendipite_votes_voisins_rapproches_u.append(calcul_facteur(MUI, pred_100_neighboors_u, \"serendipite\", 10))\n",
    "    utilite_votes_voisins_rapproches_u.append(calcul_facteur(MUI, pred_100_neighboors_u, \"utilite\", 10))\n",
    "    couverture_votes_voisins_rapproches_u.append(calcul_facteur(MUI, pred_100_neighboors_u, \"couverture\", 10))\n",
    "    nouveaute_votes_voisins_rapproches_u.append(calcul_facteur(MUI, pred_100_neighboors_u, \"nouveaute\", 10))\n",
    "    diversite_votes_voisins_rapproches_u.append(calcul_facteur(MUI, pred_100_neighboors_u, \"diversite\", 10))\n",
    "\n",
    "    serendipite_votes_sans_biais_i.append(calcul_facteur(MUI, pred_sans_biais_i, \"serendipite\", 10))\n",
    "    utilite_votes_sans_biais_i.append(calcul_facteur(MUI, pred_sans_biais_i, \"utilite\", 10))\n",
    "    couverture_votes_sans_biais_i.append(calcul_facteur(MUI, pred_sans_biais_i, \"couverture\", 10))\n",
    "    nouveaute_votes_sans_biais_i.append(calcul_facteur(MUI, pred_sans_biais_i, \"nouveaute\", 10))\n",
    "    diversite_votes_sans_biais_i.append(calcul_facteur(MUI, pred_sans_biais_i, \"diversite\", 10))\n",
    "\n",
    "    serendipite_votes_avec_biais_i.append(calcul_facteur(MUI, pred_avec_biais_i, \"serendipite\", 10))\n",
    "    utilite_votes_avec_biais_i.append(calcul_facteur(MUI, pred_avec_biais_i, \"utilite\", 10))\n",
    "    couverture_votes_avec_biais_i.append(calcul_facteur(MUI, pred_avec_biais_i, \"couverture\", 10))\n",
    "    nouveaute_votes_avec_biais_i.append(calcul_facteur(MUI, pred_avec_biais_i, \"nouveaute\", 10))\n",
    "    diversite_votes_avec_biais_i.append(calcul_facteur(MUI, pred_avec_biais_i, \"diversite\", 10))\n",
    "\n",
    "    serendipite_votes_voisins_rapproches_i.append(calcul_facteur(MUI, pred_100_neighboors_i, \"serendipite\", 10))\n",
    "    utilite_votes_voisins_rapproches_i.append(calcul_facteur(MUI, pred_100_neighboors_i, \"utilite\", 10))\n",
    "    couverture_votes_voisins_rapproches_i.append(calcul_facteur(MUI, pred_100_neighboors_i, \"couverture\", 10))\n",
    "    nouveaute_votes_voisins_rapproches_i.append(calcul_facteur(MUI, pred_100_neighboors_i, \"nouveaute\", 10))\n",
    "    diversite_votes_voisins_rapproches_i.append(calcul_facteur(MUI, pred_100_neighboors_i, \"diversite\", 10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur approche utilisateur-utilisateur sans correction de biais :\n",
      "MSE:  1.0325181206939114\n",
      "MAE:  0.8102502828117579 \n",
      "\n",
      "Erreur approche item-item sans correction de biais :\n",
      "MSE:  1.025958473178745\n",
      "MAE:  0.8061226374608481 \n",
      "\n",
      "Erreur approche utilisateur-utilisateur avec correction de biais :\n",
      "MSE:  0.9066836402736946\n",
      "MAE:  0.7498701160080046 \n",
      "\n",
      "Erreur approche item-item avec correction de biais :\n",
      "MSE:  0.8699419364048577\n",
      "MAE:  0.7354475211629607 \n",
      "\n",
      "Erreur approche utilisateur-utilisateur avec 100 voisins ajoutés :\n",
      "MSE:  0.8999437846171657\n",
      "MAE:  0.7424838568840044 \n",
      "\n",
      "Erreur approche item-item avec 100 voisins ajoutés :\n",
      "MSE:  0.8430124287359273\n",
      "MAE:  0.7212305387978677 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Erreur approche utilisateur-utilisateur sans correction de biais :\")\n",
    "print(\"MSE: \", np.mean(MSE_votes_sans_biais_u))\n",
    "print(\"MAE: \", np.mean(MAE_votes_sans_biais_u), \"\\n\")\n",
    "\n",
    "print(\"Erreur approche item-item sans correction de biais :\")\n",
    "print(\"MSE: \", np.mean(MSE_votes_sans_biais_i))\n",
    "print(\"MAE: \", np.mean(MAE_votes_sans_biais_i), \"\\n\")\n",
    "\n",
    "print(\"Erreur approche utilisateur-utilisateur avec correction de biais :\")\n",
    "print(\"MSE: \", np.mean(MSE_votes_avec_biais_u))\n",
    "print(\"MAE: \", np.mean(MAE_votes_avec_biais_u), \"\\n\")\n",
    "\n",
    "print(\"Erreur approche item-item avec correction de biais :\")\n",
    "print(\"MSE: \", np.mean(MSE_votes_avec_biais_i))\n",
    "print(\"MAE: \", np.mean(MAE_votes_avec_biais_i), \"\\n\")\n",
    "\n",
    "print(\"Erreur approche utilisateur-utilisateur avec 100 voisins ajoutés :\")\n",
    "print(\"MSE: \", np.mean(MSE_votes_voisins_rapproches_u))\n",
    "print(\"MAE: \", np.mean(MAE_votes_voisins_rapproches_u), \"\\n\")\n",
    "\n",
    "print(\"Erreur approche item-item avec 100 voisins ajoutés :\")\n",
    "print(\"MSE: \", np.mean(MSE_votes_voisins_rapproches_i))\n",
    "print(\"MAE: \", np.mean(MAE_votes_voisins_rapproches_i), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Facteur de succès de approche utilisateur-utilisateur sans correction de biais :\n",
      "utilite =  4.994869428287458\n",
      "diversite =  0.009548450526844958\n",
      "nouveaute =  9.050521918919912\n",
      "serendipite =  9.073514535825847\n",
      "couverture =  0.021521997621878716 \n",
      "\n",
      "Facteur de succès de approche item-item sans correction de biais :\n",
      "utilite =  4.363216712205541\n",
      "diversite =  0.14838623550849156\n",
      "nouveaute =  9.055951988771664\n",
      "serendipite =  9.08071872894457\n",
      "couverture =  0.21712247324613557 \n",
      "\n",
      "Facteur de succès de approche utilisateur-utilisateur avec correction de biais :\n",
      "utilite =  5.073155556109294\n",
      "diversite =  0.027848440463561618\n",
      "nouveaute =  8.781278528041863\n",
      "serendipite =  8.809027997411276\n",
      "couverture =  0.02318668252080856 \n",
      "\n",
      "Facteur de succès de approche item-item avec correction de biais :\n",
      "utilite =  5.1330118438166625\n",
      "diversite =  0.01586651025578459\n",
      "nouveaute =  8.992629503129919\n",
      "serendipite =  9.01781906396863\n",
      "couverture =  0.04684898929845423 \n",
      "\n",
      "Facteur de succès de approche utilisateur-utilisateur avec 100 voisins rapprochés :\n",
      "utilite =  5.254398092354252\n",
      "diversite =  0.11997533158324991\n",
      "nouveaute =  5.773869154543493\n",
      "serendipite =  6.072067742300689\n",
      "couverture =  0.38620689655172413 \n",
      "\n",
      "Facteur de succès de approche item-item avec 100 voisins rapprochés :\n",
      "utilite =  5.34268963118647\n",
      "diversite =  0.05986986886504394\n",
      "nouveaute =  7.736624416018293\n",
      "serendipite =  7.863219968162085\n",
      "couverture =  0.34898929845422116\n"
     ]
    }
   ],
   "source": [
    "print(\"Facteur de succès de approche utilisateur-utilisateur sans correction de biais :\")\n",
    "print(\"utilite = \", np.mean(utilite_votes_sans_biais_u))\n",
    "print(\"diversite = \", np.mean(diversite_votes_sans_biais_u))\n",
    "print(\"nouveaute = \", np.mean(nouveaute_votes_sans_biais_u))\n",
    "print(\"serendipite = \", np.mean(serendipite_votes_sans_biais_u))\n",
    "print(\"couverture = \", np.mean(couverture_votes_sans_biais_u), \"\\n\")\n",
    "\n",
    "print(\"Facteur de succès de approche item-item sans correction de biais :\")\n",
    "print(\"utilite = \", np.mean(utilite_votes_sans_biais_i))\n",
    "print(\"diversite = \", np.mean(diversite_votes_sans_biais_i))\n",
    "print(\"nouveaute = \", np.mean(nouveaute_votes_sans_biais_i))\n",
    "print(\"serendipite = \", np.mean(serendipite_votes_sans_biais_i))\n",
    "print(\"couverture = \", np.mean(couverture_votes_sans_biais_i), \"\\n\")\n",
    "\n",
    "print(\"Facteur de succès de approche utilisateur-utilisateur avec correction de biais :\")\n",
    "print(\"utilite = \", np.mean(utilite_votes_avec_biais_u))\n",
    "print(\"diversite = \", np.mean(diversite_votes_avec_biais_u))\n",
    "print(\"nouveaute = \", np.mean(nouveaute_votes_avec_biais_u))\n",
    "print(\"serendipite = \", np.mean(serendipite_votes_avec_biais_u))\n",
    "print(\"couverture = \", np.mean(couverture_votes_avec_biais_u), \"\\n\")\n",
    "\n",
    "print(\"Facteur de succès de approche item-item avec correction de biais :\")\n",
    "print(\"utilite = \", np.mean(utilite_votes_avec_biais_i))\n",
    "print(\"diversite = \", np.mean(diversite_votes_avec_biais_i))\n",
    "print(\"nouveaute = \", np.mean(nouveaute_votes_avec_biais_i))\n",
    "print(\"serendipite = \", np.mean(serendipite_votes_avec_biais_i))\n",
    "print(\"couverture = \", np.mean(couverture_votes_avec_biais_i), \"\\n\")\n",
    "\n",
    "print(\"Facteur de succès de approche utilisateur-utilisateur avec 100 voisins rapprochés :\")\n",
    "print(\"utilite = \", np.mean(utilite_votes_voisins_rapproches_u))\n",
    "print(\"diversite = \", np.mean(diversite_votes_voisins_rapproches_u))\n",
    "print(\"nouveaute = \", np.mean(nouveaute_votes_voisins_rapproches_u))\n",
    "print(\"serendipite = \", np.mean(serendipite_votes_voisins_rapproches_u))\n",
    "print(\"couverture = \", np.mean(couverture_votes_voisins_rapproches_u), \"\\n\")\n",
    "\n",
    "print(\"Facteur de succès de approche item-item avec 100 voisins rapprochés :\")\n",
    "print(\"utilite = \", np.mean(utilite_votes_voisins_rapproches_i))\n",
    "print(\"diversite = \", np.mean(diversite_votes_voisins_rapproches_i))\n",
    "print(\"nouveaute = \", np.mean(nouveaute_votes_voisins_rapproches_i))\n",
    "print(\"serendipite = \", np.mean(serendipite_votes_voisins_rapproches_i))\n",
    "print(\"couverture = \", np.mean(couverture_votes_voisins_rapproches_i))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "78b5abffec9e75b5ff9af6e5e7048028f3e068e444301b74fc962c40f0630069"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
